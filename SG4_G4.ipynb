{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dEJG6iOPnnp"
      },
      "outputs": [],
      "source": [
        "# Pre-processing pipeline\n",
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "import spacy\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"Dutch_Migration_News.csv\")\n",
        "\n",
        "# Expected columns\n",
        "TITLE_COL = \"title\"\n",
        "BODY_COL  = \"body\"\n",
        "\n",
        "df[TITLE_COL] = df[TITLE_COL].astype(str)\n",
        "df[BODY_COL]  = df[BODY_COL].astype(str)\n",
        "\n",
        "# Combine title + body\n",
        "df[\"text\"] = df[TITLE_COL] + \" \" + df[BODY_COL]\n",
        "\n",
        "# Load SpaCy model (Dutch)\n",
        "# Run once in your own environment if not installed:\n",
        "#!python -m spacy download nl_core_news_sm\n",
        "nlp = spacy.load(\"nl_core_news_sm\")\n",
        "\n",
        "# preprocessing function\n",
        "# - POS filtering\n",
        "# - Lemmatization\n",
        "# - Stopword removal\n",
        "# - Remove punctuation & digits\n",
        "# - Lowercasing\n",
        "\n",
        "def clean_text_spacy(doc):\n",
        "    include_pos = [\"NOUN\", \"PROPN\", \"ADJ\", \"VERB\"]\n",
        "\n",
        "    text = \" \".join([\n",
        "        t.lemma_.strip()\n",
        "        for t in doc\n",
        "        if t.pos_ in include_pos and not t.is_stop\n",
        "    ])\n",
        "\n",
        "    # remove punctuation\n",
        "    text = text.translate(str.maketrans(\" \", \" \", string.punctuation))\n",
        "    # remove digits\n",
        "    text = text.translate(str.maketrans(\" \", \" \", string.digits))\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply SpaCy pipeline\n",
        "df[\"text_nlp\"] = df[\"text\"].apply(lambda x: nlp(x))\n",
        "df[\"clean_text\"] = df[\"text_nlp\"].apply(clean_text_spacy)\n",
        "\n",
        "# Token list version (useful for LDA?)\n",
        "df[\"clean_tokens\"] = df[\"clean_text\"].apply(lambda x: x.split())\n",
        "\n",
        "# Quick sanity check\n",
        "\n",
        "df[[\"text\", \"clean_text\", \"clean_tokens\"]].head()"
      ]
    }
  ]
}
